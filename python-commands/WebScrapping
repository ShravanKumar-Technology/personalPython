webbrowser. Comes with Python and opens a browser to a specific page.

Requests. Downloads files and web pages from the Internet.

Beautiful Soup. Parses HTML, the format that web pages are written in.

Selenium. Launches and controls a web browser. Selenium is able to fill in forms and simulate mouse clicks in this browser.
---------------------------------------------------------------------------------------------------------------------------



The webbrowser module’s open() function can launch a new browser to a specified URL. 

>>> import webbrowser
>>> webbrowser.open('http://inventwithpython.com/')

A web browser tab will open to the URL http://inventwithpython.com/. This is about the only thing the webbrowser module can do.



Downloading Files from the Web with the requests Module:

>>> import requests

Downloading a Web Page with the requests.get() Function

>>> import requests
   >>> res = requests.get('https://automatetheboringstuff.com/files/rj.txt')
   >>> type(res)
   <class 'requests.models.Response'>
❶ >>> res.status_code == requests.codes.ok
   True
   >>> len(res.text)
   178981
   >>> print(res.text[:250])
   The Project Gutenberg EBook of Romeo and Juliet, by William Shakespeare

   This eBook is for the use of anyone anywhere at no cost and with
   almost no restrictions whatsoever. You may copy it, give it away or
   re-use it under the terms of the Proje


Checking for Errors

>>> res = requests.get('http://inventwithpython.com/page_that_does_not_exist')
>>> res.raise_for_status()
Traceback (most recent call last):
  File "<pyshell#138>", line 1, in <module>
    res.raise_for_status()
  File "C:\Python34\lib\site-packages\requests\models.py", line 773, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found
The raise_for_status() method is a good way to ensure that a program halts if a bad download occurs. 


---------------------------------------------------OR------------------------------------------------------------------

If a failed download isn’t a deal breaker for your program, you can wrap the raise_for_status() line with try and except statements to handle this error case without crashing.


import requests
res = requests.get('http://inventwithpython.com/page_that_does_not_exist')
try:
    res.raise_for_status()
except Exception as exc:
    print('There was a problem: %s' % (exc))
This raise_for_status() method call causes the program to output the following:


There was a problem: 404 Client Error: Not Found

Always call raise_for_status() after calling requests.get(). You want to be sure that the download has actually worked before your program continues.




Saving Downloaded Files to the Hard Drive:


To write the web page to a file, you can use a for loop with the Response object’s iter_content() method.


>>> import requests
>>> res = requests.get('https://automatetheboringstuff.com/files/rj.txt')
>>> res.raise_for_status()
>>> playFile = open('RomeoAndJuliet.txt', 'wb')
>>> for chunk in res.iter_content(100000):
        playFile.write(chunk)

100000
78981
>>> playFile.close()

To review, here’s the complete process for downloading and saving a file:

Call requests.get() to download the file.

Call open() with 'wb' to create a new file in write binary mode.

Loop over the Response object’s iter_content() method.

Call write() on each iteration to write the content to the file.

Call close() to close the file.

-------------------------------------------------------------------------------------------------------------------------

Parsing HTML with the BeautifulSoup Module:

>>> import requests, bs4
>>> res = requests.get('http://nostarch.com')
>>> res.raise_for_status()
>>> noStarchSoup = bs4.BeautifulSoup(res.text)
>>> type(noStarchSoup)
<class 'bs4.BeautifulSoup'>

You can also load an HTML file from your hard drive by passing a File object to bs4.BeautifulSoup(). Enter the following into the interactive shell (make sure the example.html file is in the working directory):


>>> exampleFile = open('example.html')
>>> exampleSoup = bs4.BeautifulSoup(exampleFile)
>>> type(exampleSoup)
<class 'bs4.BeautifulSoup'>
Once you have a BeautifulSoup object, you can use its methods to locate specific parts of an HTML document.


Finding an Element with the select() Method:

('https://automatetheboringstuff.com/chapter11/#calibre_link-8')

>>> import bs4
>>> exampleFile = open('example.html')
>>> exampleSoup = bs4.BeautifulSoup(exampleFile.read())
>>> elems = exampleSoup.select('#author')
>>> type(elems)
<class 'list'>
>>> len(elems)
1
>>> type(elems[0])
<class 'bs4.element.Tag'>
>>> elems[0].getText()
'Al Sweigart'
>>> str(elems[0])
'<span id="author">Al Sweigart</span>'
>>> elems[0].attrs
{'id': 'author'}


This code will pull the element with id="author" out of our example HTML. We use select('#author') to return a list of all the elements with id="author". We store this list of Tag objects in the variable elems, and len(elems) tells us there is one Tag object in the list; there was one match. Calling getText() on the element returns the element’s text, or inner HTML. The text of an element is the content between the opening and closing tags: in this case, 'Al Sweigart'.

Passing the element to str() returns a string with the starting and closing tags and the element’s text. Finally, attrs gives us a dictionary with the element’s attribute, 'id', and the value of the id attribute, 'author'.

You can also pull all the <p> elements from the BeautifulSoup object. Enter this into the interactive shell:


>>> pElems = exampleSoup.select('p')
>>> str(pElems[0])
'<p>Download my <strong>Python</strong> book from <a href="http://
inventwithpython.com">my website</a>.</p>'
>>> pElems[0].getText()
'Download my Python book from my website.'
>>> str(pElems[1])
'<p class="slogan">Learn Python the easy way!</p>'
>>> pElems[1].getText()
'Learn Python the easy way!'
>>> str(pElems[2])
'<p>By <span id="author">Al Sweigart</span></p>'
>>> pElems[2].getText()
'By Al Sweigart'
This time, select() gives us a list of three matches, which we store in pElems. Using str() on pElems[0], pElems[1], and pElems[2] shows you each element as a string, and using getText() on each element shows you its text.













